{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING RETE NEURALE - classificazione captcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform\n",
    "import torchvision.transforms as T\n",
    "# Define single transforms\n",
    "\n",
    "# Note: transforms can also be regular functions\n",
    "def normalize_(x):\n",
    "    # Set values\n",
    "    x[x > 0.5] = 1\n",
    "    x[x <= 0.5] = -1\n",
    "    # Return\n",
    "    return x\n",
    "\n",
    "\n",
    "normalize = normalize_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize 48x48\n",
    "def resize_(img):   \n",
    "    size = 48,48\n",
    "    img = img.resize(size)\n",
    "    return img\n",
    "\n",
    "resize = resize_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Grayscale(num_output_channels=1),\n",
    "                       resize,\n",
    "                       T.ToTensor(),\n",
    "                       normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class map\n",
    "class_names = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I',9:\"J\",10:\"K\",11:\"L\",12:\"M\",13:\"N\",14:\"O\",15:\"P\",16:\"Q\",17:\"R\",18:\"S\",19:\"T\",20:\"U\",21:\"V\",22:\"W\",23:\"X\",24:\"Y\",25:\"Z\"};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "#string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from PIL import Image, ImageChops\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "root_dir = \"./output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convolutional layer\n",
    "class ConvLayer(nn.Sequential):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.add_module('conv', nn.Conv2d(in_features, out_features, kernel_size=3))\n",
    "        self.add_module('relu', nn.ReLU())\n",
    "        self.add_module('pool', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "# Convolutional layer\n",
    "class ConvLayerBN(nn.Sequential):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.add_module('conv', nn.Conv2d(in_features, out_features, kernel_size=3))\n",
    "        self.add_module('relu', nn.ReLU())\n",
    "        self.add_module('bn', nn.BatchNorm2d(out_features))\n",
    "        self.add_module('pool', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "# Define model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call parent\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.convs = nn.Sequential(\n",
    "            ConvLayerBN(1, 32),\n",
    "            ConvLayerBN(32, 128)\n",
    "        )\n",
    "        # Computing encoding size\n",
    "        self.convs.eval()\n",
    "        test_x = torch.zeros(1, 1, 48,48) #DIMENSIONE IN PIXEL\n",
    "        test_x = self.convs(test_x)\n",
    "        encoding_size = test_x.numel()\n",
    "        print(f\"Encoding size: {encoding_size}\")\n",
    "        # FC layers\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(encoding_size, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, len(class_names))\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Compute output\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fcs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import PIL\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "# Instantiate datasets\n",
    "letter_train_dataset = ImageFolder(os.path.join(root_dir,  \"train\"), transform) #, loader=loader)\n",
    "letter_val_dataset = ImageFolder(os.path.join(root_dir,  \"val\"), transform) #, loader=loader)\n",
    "letter_test_dataset = ImageFolder(os.path.join(root_dir,  \"test\"), transform) #, loader=loader)\n",
    "\n",
    "# Get number of classes (we'll need it in the model)\n",
    "num_classes = len(letter_train_dataset.classes)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Num. classes: {num_classes}\")\n",
    "print(f\"Num. train samples: {len(letter_train_dataset)}\")\n",
    "print(f\"Num. valid. samples: {len(letter_val_dataset)}\")\n",
    "print(f\"Num. test samples: {len(letter_test_dataset)}\")\n",
    "\n",
    "\n",
    "# Instantiate data loaders\n",
    "loaders = {\"train\": DataLoader(dataset=letter_train_dataset, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True),\n",
    "           \"val\":   DataLoader(dataset=letter_val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\n",
    "           \"test\":  DataLoader(dataset=letter_test_dataset,  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "start_epoch = 0\n",
    "checkpoint = f\"checkpoint-{start_epoch}.pth\"\n",
    "use_checkpoint = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check checkpoint\n",
    "if use_checkpoint:\n",
    "    state_dict = torch.load(checkpoint)\n",
    "else:\n",
    "    start_epoch = 0\n",
    "\n",
    "# Create model for training\n",
    "model = Model()\n",
    "if use_checkpoint:\n",
    "    model.load_state_dict(state_dict)\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = letter_train_dataset[0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "num_epochs = 30\n",
    "save_every = 1\n",
    "\n",
    "# Initialize training history\n",
    "\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy\n",
    "   \n",
    "    # Save checkpoint\n",
    "    if epoch % save_every == 0:\n",
    "        state_dict = model.state_dict()\n",
    "        for k,v in state_dict.items():\n",
    "            state_dict[k] = v.cpu() #conversione CUDA - CPU\n",
    "        torch.save(state_dict, f\"checkpoint-{epoch}.pth\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "# Define root directory\n",
    "save_path = f\"./modello{num_epochs}.pt\"\n",
    "modello_salvato = model.state_dict()\n",
    "torch.save(modello_salvato, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "Testing del modello trainato. Prima si generano dei captcha casuali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding size: 12800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (convs): Sequential(\n",
       "    (0): ConvLayerBN(\n",
       "      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvLayerBN(\n",
       "      (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (0): Linear(in_features=12800, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=2048, out_features=26, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"./modello30.pt\",map_location=dev))\n",
    "model.eval()\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import string\n",
    "def getfirstUppercase(s):\n",
    "    return ([char for char in s if char.isupper()])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sporca(path):\n",
    "    dirs = os.listdir( path )\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            im = noisy(im,width=1000,height=200)\n",
    "            im.save(f\"{f}.png\")\n",
    "\n",
    "def noisy(img,width,height):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for x in range(0,15):\n",
    "        draw.point((random.randint(0,width),random.randint(0,height)),0)\n",
    "        draw.line([(random.randint(0,width),random.randint(0,height)), (random.randint(0,width),random.randint(0,height))],width=3)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./matrici/originale/output/\"\n",
    "dirs = os.listdir( path )\n",
    "if not os.path.exists(\"./CaptchaTest/\"):\n",
    "    os.makedirs(\"./CaptchaTest/\")\n",
    "\n",
    "total_width = 1000\n",
    "max_height = 200\n",
    "for v in range (0,5):\n",
    "    new_im = Image.new(\"1\", (total_width, max_height))\n",
    "    filename = \"\"\n",
    "    x_offset = 0\n",
    "    list_images = []\n",
    "    for i in range (0,5): #5 elementi\n",
    "        curr_rand=random.randint(0,len(dirs)-1)\n",
    "        list_images.append(path+dirs[curr_rand])\n",
    "        valore = dirs[curr_rand]\n",
    "        filename+=getfirstUppercase(valore)\n",
    "\n",
    "    for im in list_images:\n",
    "        image_cur = Image.open(im)\n",
    "        new_im.paste(image_cur, (x_offset,0))\n",
    "        x_offset += image_cur.size[0]\n",
    "\n",
    "    new_im.save(f'./CaptchaTest/{filename}{v}.png') # es stringa AEDTG45.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: R  with accuracy of: 55.12\n",
      "Predicted: Y  with accuracy of: 54.73\n",
      "Predicted: T  with accuracy of: 98.88\n",
      "Predicted: H  with accuracy of: 92.09\n",
      "Predicted: N  with accuracy of: 88.92\n",
      "Predicted: G  with accuracy of: 97.52\n",
      "Predicted: G  with accuracy of: 99.26\n",
      "Predicted: D  with accuracy of: 99.89\n",
      "Predicted: N  with accuracy of: 92.13\n",
      "Predicted: F  with accuracy of: 70.52\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x000000000BADA1E0> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     37\u001b[0m             display(\n\u001b[0;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             )\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<D:\\Anaconda3\\lib\\site-packages\\decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2073\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2074\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2075\u001b[1;33m                     **kwargs)\n\u001b[0m\u001b[0;32m   2076\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2077\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \"\"\"\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[0mtoolbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoolbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;31m# don't forget to call the superclass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 1649\u001b[1;33m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[0;32m   1650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2626\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2628\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[1;32m--> 584\u001b[1;33m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[0;32m    585\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mmake_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    829\u001b[0m         return self._make_image(\n\u001b[0;32m    830\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m             unsampled=unsampled)\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    510\u001b[0m                 \u001b[0malpha_channel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m                 alpha_channel[:] = np.asarray(\n\u001b[1;32m--> 512\u001b[1;33m                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mout_alpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m                     np.uint8)\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "prova_dir = \"./CaptchaTest/\"\n",
    "\n",
    "img = Image.open(os.path.join(prova_dir,\"AYTHNGGDNF498.png\"))\n",
    "\n",
    "width, _ = img.size\n",
    "\n",
    "label = \"\"\n",
    "\n",
    "num_lett = int(width/200)\n",
    "\n",
    "for i in range(0,num_lett):\n",
    "    plt.figure(figsize=(2, 2)) #deve stare dentro per plottare le tre immmagini\n",
    "    img = Image.open(os.path.join(prova_dir,\"AYTHNGGDNF498.png\"))\n",
    "    img = img.convert('1')\n",
    "    #crop ogni 200px 5 volte\n",
    "    #0,0 200,200 - 200,0 400,200 - 400,0 600, 200\n",
    "    current_box = img.crop((200*i,0,200*(i+1),200))\n",
    "\n",
    "    input = transform(current_box)\n",
    "    plt.imshow(current_box)\n",
    "    # Predict class\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input.unsqueeze(0).to(dev))\n",
    "    accuracy = output.softmax(1).max(1)\n",
    "    accuracy = accuracy[0].item()*100\n",
    "    _,pred = output.max(1)\n",
    "    pred = pred.item()\n",
    "    print(f\"Predicted: {class_names[pred]}  with accuracy of: {'%.2f'%(accuracy)}\")\n",
    "    #print(\"secondo\", f\"{'%.2f'%(secondo)}\")\n",
    "    #plt.show(input)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill with borders\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/python-utils-scripts/test-folder/\"\n",
    "\n",
    "img = Image.open(prova_dir+\"preview7.png\")\n",
    "plt.imshow(img)\n",
    "\n",
    "img_with_border = ImageOps.expand(img,border=49,fill='black')\n",
    "plt.imshow(img_with_border)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esempio con test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/\"\n",
    "\n",
    "\n",
    "#transform = T.Compose([T.Grayscale(num_output_channels=1),\n",
    "                       #T.ToTensor(),\n",
    "                       #normalize])\n",
    "\n",
    "\n",
    "#input, label = Image.open(prova_dir+\"TEST42rgb.png\")\n",
    "\n",
    "# Get random sample from test set\n",
    "#idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[0]\n",
    "\n",
    "# Normalize and show image\n",
    "#input_show = (input - input.min())/(input.max() - input.min())\n",
    "#plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "#plt.imshow(input_show)\n",
    "#plt.axis('off')\n",
    "\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input.unsqueeze(0).to(dev))\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a model for dog detection\n",
    "\n",
    "In fine-tuning, we will include layers from a pre-trained model into our own network, then train the whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the `features` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test input\n",
    "alexnet.eval()\n",
    "test_x = torch.zeros(1, 3, 224, 224).to(dev)\n",
    "# Forward whole model\n",
    "print(alexnet(test_x).size())\n",
    "# Forward features only\n",
    "print(alexnet.features(test_x).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fine-tuned model\n",
    "class FineTunedAlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load AlexNet model\n",
    "        alexnet = models.alexnet(pretrained=True)\n",
    "        # Select feature extraction part\n",
    "        self.features = alexnet.features\n",
    "        self.fc1 = nn.Linear(256*6*6, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.output = nn.Linear(2048, 133)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.output(x),1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = FineTunedAlexNet()\n",
    "model = model.to(dev);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = dog_train_dataset[0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize training history\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get random sample from test set\n",
    "idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[idx]\n",
    "# Normalize and show image\n",
    "input_show = (input - input.min())/(input.max() - input.min())\n",
    "plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "plt.axis('off')\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input.unsqueeze(0).to(dev))\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using a pre-trained model as a feature extractor\n",
    "\n",
    "Fully-connected layer of models pre-trained on ImageNet can also work as generic image descriptors, because they compactly represent image content.\n",
    "\n",
    "Feature extraction means that we pass an image to a CNN model, but only get the output of a fully-connected layer, and use that output instead of the fully image. Then, we train a simpler classifier (SVM or MLP) on the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction in PyTorch may be tricky sometimes, depending on how the model is defined. We will see two methods to extract features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Modifying layers\n",
    "\n",
    "Let's see the Alexnet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "alexnet.eval()\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "alexnet(torch.zeros(1, 3, 224, 224).to(dev)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's suppose we want the output of the last FC layer (before classification). In practice, we want the output of layer `5` inside the `classifier` block. The problem is that `classifier` is a `Sequential`, so we cannot directly get the output of an intermediate layer.\n",
    "\n",
    "One solution is to modify the `classifier` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classifier block\n",
    "alexnet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential children\n",
    "alexnet.classifier.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert generator to list\n",
    "list(alexnet.classifier.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the final linear layer\n",
    "new_classifier_modules = list(alexnet.classifier.children())\n",
    "new_classifier_modules = new_classifier_modules[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the new list of modules\n",
    "new_classifier_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Sequential container\n",
    "new_classifier = nn.Sequential(*new_classifier_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the classifier\n",
    "alexnet.classifier = new_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "test_out = alexnet(torch.zeros(1, 3, 224, 224).to(dev))\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep output for later\n",
    "features_1 = test_out.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, our `alexnet` model now returns directly the output of a fully-connected layer. However, this was easy because `classifier` is the last block of the model, so there's nothing after it that depends on it.\n",
    "\n",
    "In other cases, it may not be so easy. For example, consider the [`inception_v3`](https://github.com/pytorch/vision/blob/master/torchvision/models/inception.py) model.\n",
    "\n",
    "In that case, layers are defined as individual class properties, and the `forward()` method calls them in turn. If we want to extract features, we should modify the `forward()` method. It can be done, but it's not trivial, and there's a cleaner way: **hooks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Forward hooks\n",
    "\n",
    "Hooks are callback functions associated to `nn.Module`s, that are invoked during forward (_forward hook_) or during backpropagation (_backward hook_).\n",
    "\n",
    "When you _register_ a hook, you ask the model to call your function whenever a layer processes input data. Your function will receive the input and output of the module.\n",
    "\n",
    "Another way to implement feature extraction is to set up a forward hook on our target layer, get the layer's output, and save it in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "alexnet.eval()\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction class\n",
    "class FeatureExtractor:\n",
    "    \n",
    "    # Constructor: receives model and target layer\n",
    "    def __init__(self, model, layer):\n",
    "        # Save model\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        # Internal variable to store target features\n",
    "        self.features = None\n",
    "        # Define hook\n",
    "        def forward_hook(module, input, output):\n",
    "            # Copy features\n",
    "            self.features = output.clone()\n",
    "        # Register hook\n",
    "        layer.register_forward_hook(forward_hook)\n",
    "        \n",
    "    # Function interface\n",
    "    def __call__(self, input):\n",
    "        with torch.no_grad():\n",
    "            # Forward through model\n",
    "            self.model(input)\n",
    "        # Return features\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get reference to target layer?\n",
    "\n",
    "Just traverse the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extractor\n",
    "feat_extr = FeatureExtractor(alexnet, alexnet.classifier[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "test_out = feat_extr(torch.zeros(1, 3, 224, 224).to(dev))\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare features\n",
    "features_2 = test_out\n",
    "print((features_1 - features_2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our feature extraction to process all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of features\n",
    "num_features = feat_extr(dog_train_dataset[0][0].unsqueeze(0).to(dev)).numel()\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data matrices (num_samples x num_features)\n",
    "datasets = {\"train\": dog_train_dataset, \"val\": dog_val_dataset, \"test\": dog_test_dataset}\n",
    "features = {\"train\": torch.Tensor(len(dog_train_dataset), num_features),\n",
    "            \"val\":   torch.Tensor(len(dog_val_dataset), num_features),\n",
    "            \"test\":  torch.Tensor(len(dog_test_dataset), num_features)\n",
    "           }\n",
    "labels = {\"train\": torch.LongTensor(len(dog_train_dataset)),\n",
    "          \"val\":   torch.LongTensor(len(dog_val_dataset)),\n",
    "          \"test\":  torch.LongTensor(len(dog_test_dataset))\n",
    "         }\n",
    "# Fill the features for each split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"Processing {split} split\")\n",
    "    # Process each sample in the split\n",
    "    for i in range(len(datasets[split])):\n",
    "        # Get sample\n",
    "        sample,label = datasets[split][i]\n",
    "        # Compute features\n",
    "        sample = sample.unsqueeze(0).to(dev)\n",
    "        feats = feat_extr(sample)\n",
    "        # Copy features\n",
    "        features[split][i] = feats\n",
    "        labels[split][i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our data formatted as in our initial examples with linear regression and classification. However, we can still use the standard `DataLoader` interface, by wrapping our matrices as `TensorDataset` objects. In a `TensorDataset`, you can pass any kind of tensors as source data, and sample selection is performed by indexing the first dimension (in our case, rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from torch.utils.data import TensorDataset\n",
    "# Prepare tensor datasets\n",
    "tensor_datasets = {\n",
    "    split: TensorDataset(features[split], labels[split]) for split in features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data loaders\n",
    "loaders = {\"train\": DataLoader(dataset=tensor_datasets[\"train\"], batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True),\n",
    "           \"val\":   DataLoader(dataset=tensor_datasets[\"val\"],   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\n",
    "           \"test\":  DataLoader(dataset=tensor_datasets[\"test\"],  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a linear classifier on the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = nn.Linear(num_features, num_classes)\n",
    "model = model.to(dev);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = tensor_datasets[\"train\"][0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training history\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get random sample from test set\n",
    "idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[idx]\n",
    "# Normalize and show image\n",
    "input_show = (input - input.min())/(input.max() - input.min())\n",
    "plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "plt.axis('off')\n",
    "# Extract features\n",
    "input = feat_extr(input.unsqueeze(0).to(dev))\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input)\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "author": "ML1819",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
