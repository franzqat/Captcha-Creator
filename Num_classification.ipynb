{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING RETE NEURALE - classificazione captcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform\n",
    "import torchvision.transforms as T\n",
    "# Define single transforms\n",
    "\n",
    "# Note: transforms can also be regular functions\n",
    "def normalize_(x):\n",
    "    # Set values\n",
    "    x[x > 0.5] = 1\n",
    "    x[x <= 0.5] = -1\n",
    "    # Return\n",
    "    return x\n",
    "\n",
    "\n",
    "normalize = normalize_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_(img):   #resize 48x48 \n",
    "    size = 48,48\n",
    "    img = img.resize(size)\n",
    "    return img\n",
    "\n",
    "resize = resize_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Grayscale(num_output_channels=1),\n",
    "                       resize,\n",
    "                       T.ToTensor(),\n",
    "                       normalize])\n",
    "\n",
    "                       #,T.Normalize(mean=0,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet class map\n",
    "class_names = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9'};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from PIL import Image, ImageChops\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Dog Detector\n",
    "\n",
    "While looking at the class list, you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained, we need only to check if the returned class prediction is a value between 151 and 268 (inclusive).\n",
    "\n",
    "We use these ideas to define the `dog_detector` function below, which returns `True` if a dog is detected in an image (and `False` if not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./captcha/singoli/output\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "root_dir = \"./captcha/singoli/output\"\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now, we will create a CNN that classifies numbers. We will train our model _from scratch_, i.e. with randomly-initialized weights.\n",
    "\n",
    "The task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have great difficulty in distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. classes: 9\n",
      "Num. train samples: 22500\n",
      "Num. valid. samples: 4500\n",
      "Num. test samples: 18000\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import PIL\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "# Instantiate datasets\n",
    "dog_train_dataset = ImageFolder(os.path.join(root_dir,  \"train\"), transform) #, loader=loader)\n",
    "dog_val_dataset = ImageFolder(os.path.join(root_dir,  \"val\"), transform) #, loader=loader)\n",
    "dog_test_dataset = ImageFolder(os.path.join(root_dir,  \"test\"), transform) #, loader=loader)\n",
    "\n",
    "# Get number of classes (we'll need it in the model)\n",
    "num_classes = len(dog_train_dataset.classes)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Num. classes: {num_classes}\")\n",
    "print(f\"Num. train samples: {len(dog_train_dataset)}\")\n",
    "print(f\"Num. valid. samples: {len(dog_val_dataset)}\")\n",
    "print(f\"Num. test samples: {len(dog_test_dataset)}\")\n",
    "\n",
    "\n",
    "# Instantiate data loaders\n",
    "loaders = {\"train\": DataLoader(dataset=dog_train_dataset, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True),\n",
    "           \"val\":   DataLoader(dataset=dog_val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\n",
    "           \"test\":  DataLoader(dataset=dog_test_dataset,  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 48])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convolutional layer\n",
    "class ConvLayer(nn.Sequential):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.add_module('conv', nn.Conv2d(in_features, out_features, kernel_size=3))\n",
    "        self.add_module('relu', nn.ReLU())\n",
    "        self.add_module('pool', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "# Convolutional layer\n",
    "class ConvLayerBN(nn.Sequential):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.add_module('conv', nn.Conv2d(in_features, out_features, kernel_size=3))\n",
    "        self.add_module('relu', nn.ReLU())\n",
    "        self.add_module('bn', nn.BatchNorm2d(out_features))\n",
    "        self.add_module('pool', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "# Define model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call parent\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.convs = nn.Sequential(\n",
    "            ConvLayerBN(1, 32),\n",
    "            ConvLayerBN(32, 128)#,\n",
    "           # ConvLayerBN(256, 256),\n",
    "          #  ConvLayerBN(256, 512),\n",
    "          #  ConvLayerBN(512, 512)\n",
    "        )\n",
    "        # Computing encoding size\n",
    "        self.convs.eval()\n",
    "        #test_x = torch.zeros(1, 3, 224, 244)\n",
    "        #test_x = torch.zeros(1, 1, 32,32)\n",
    "        test_x = torch.zeros(1, 1, 48,48) ##GUARDACASO E' LA DIMENSIONE IN PIXEL\n",
    "        test_x = self.convs(test_x)\n",
    "        encoding_size = test_x.numel()\n",
    "        print(f\"Encoding size: {encoding_size}\")\n",
    "        # FC layers\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(encoding_size, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Compute output\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fcs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding size: 12800\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-17f968a47752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-3015bc6bddb9>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         )\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = Model()\n",
    "model = model.to(dev);\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-837f1cad0a17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test model output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdog_train_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model output size:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = dog_train_dataset[0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, TL=1.4266, TA=0.6927, VL=0.5801, VA=0.9354, ŦL=0.5737, ŦA=0.9360\n",
      "Epoch: 2, TL=0.4275, TA=0.9280, VL=0.2102, VA=0.9694, ŦL=0.2066, ŦA=0.9696\n",
      "Epoch: 3, TL=0.2111, TA=0.9604, VL=0.1217, VA=0.9776, ŦL=0.1200, ŦA=0.9791\n",
      "Epoch: 4, TL=0.1389, TA=0.9729, VL=0.0861, VA=0.9827, ŦL=0.0851, ŦA=0.9829\n",
      "Epoch: 5, TL=0.1052, TA=0.9781, VL=0.0662, VA=0.9849, ŦL=0.0661, ŦA=0.9866\n"
     ]
    }
   ],
   "source": [
    "# Initialize training history\n",
    "\n",
    "\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.9866\n"
     ]
    }
   ],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "# Define root directory\n",
    "save_path = \"F:/Programmazione/UO-Captcha-breaker/modello-48-1bpp-cropresize.pt\"\n",
    "modello_salvato = model.state_dict()\n",
    "torch.save(modello_salvato, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/python-utils-scripts/\"\n",
    "\n",
    "\n",
    "transform_test = T.Compose([T.Grayscale(num_output_channels=1),\n",
    "                           trim,\n",
    "                           T.ToTensor(),\n",
    "                           normalize])\n",
    "\n",
    "\n",
    "img = Image.open(prova_dir+\"prova-113.png\")\n",
    "img = transform_test(img)\n",
    "print(img.size())\n",
    "\n",
    "\n",
    "img = Image.open(prova_dir+\"prova-bin-resized.png\")\n",
    "img = transform_test(img)\n",
    "print(img.size())\n",
    "#plt.imshow(img)\n",
    "#size = 32,32\n",
    "#img = img.resize(size)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 8 (correct: )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/python-utils-scripts/test-folder/\"\n",
    "\n",
    "img = Image.open(prova_dir+\"preview12.png\")\n",
    "plt.imshow(img)\n",
    "img = img.convert('1')\n",
    "\n",
    "\"\"\"\n",
    "img = trim(img)\n",
    "size = 48,48\n",
    "img = img.resize(size)\n",
    "\"\"\"\n",
    "plt.imshow(img)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "transform_imageprova = T.Compose([\n",
    "                    T.Grayscale(num_output_channels=1),\n",
    "                    #resize_,\n",
    "                    trim,\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                    ])\n",
    "\"\"\"\n",
    "# Transform image\n",
    "#img = transform_imageprova(img)\n",
    "\n",
    "label = \"\"\n",
    "input = transform(img)\n",
    "#input = transform(img)\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input.unsqueeze(0).to(dev))\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {class_names[pred]} (correct: {label})\")\n",
    "#plt.show(input)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xc09ca20>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD8CAYAAABEiVmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAElpJREFUeJzt3X+sm1d9x/H3Z4XWGSDlFmh3l4blBgV0C38kpSqVgKobA9q7icAkWNAE0VYtIBGJTlQiUGmrtn8Ga0FCqcqC2pFOXQsblEZVGHQZP/5gLU2bkLYzoWlvoJd4ySiXtoANS/nuj+f44tzcH/b142v7+POSLNvHj+2v5XzyPD73POcoIjCzvPxWvwsws/I52GYZcrDNMuRgm2XIwTbLkINtlqGeBVvSVZKOSjomaVev3sfMzqZe/B1b0jnA94G3ADPAg8B7IuK/S38zMztLr/bYlwHHIuLJiPgVcBewtUfvZWbzvKBHr7sOeKrl/gzw+sU2luThb2bt+XFEvHy5jXoVbC3QdkZ4Je0AdvTo/c1y9YN2NupVsGeA9S33LwJOtG4QEXuAPeA9tlnZevUb+0Fgk6QJSecC24B9PXovM5unJ3vsiDgtaSfwVeAc4LaIeKwX72VmZ+vJn7s6LsKH4mbteigiLl1uI488M8uQg22WIQfbLEMOtlmGHGyzDDnYZhlysM0y5GCbZcjBNsuQg22WIQfbLEMOtlmGHGyzDDnYZhlysM0ytOJgS1ov6euSqpIek/Sh1H6DpB9JOpwuU+WVa2bt6GYGldPAhyPiYUkvAR6SdF967FMRcWP35ZnZSqw42BFRA2rp9nOSqhTTDptZn5XyG1vSBmAL8EBq2inpiKTbJI2V8R5m1r6ugy3pxcAXgWsj4lngFuCVwGaKPfpNizxvh6SDkg52W4OZnamryQwlvRC4F/hqRHxygcc3APdGxGuXeR1PZmjWnt5OZihJwK1AtTXUksZbNnsn8OhK38PMVqabXvE3AO8FHpF0OLV9DHiPpM0US/ocB97fVYVm1jHPK242XDyvuNmocrDNMuRgm2XIwTbLkINtliEH2yxDDrZZhhxssww52GYZcrDNMuRgm2XIwTbLkINtliEH2yxDDrZZhhxsswx1M4MKAJKOA88BzwOnI+JSSecDnwc2UMyi8u6ImO32vcysPWXtsX8/Ija3zOywCzgQEZuAA+m+ma2SrvfYi9gKXJlu7wW+AXykR+81ACr9LsDa1uh3AauijD12AF+T9JCkHantwrRSSHPFkAvmP8nzipv1Thl77DdExAlJFwD3SfpeO0+KiD3AHvBkhmZl63qPHREn0vUp4G7gMuBkc37xdH2q2/cxs/Z1FWxJL0orbSLpRcBbKRYI2AdsT5ttB+7p5n3MrDPdHopfCNxdLArCC4B/iYh/l/Qg8AVJ1wA/BN7V5fuYWQe8YEAp3Cs+PIa+V9wLBpiNKgfbLEMOtlmGHGyzDDnYZhlysM0y5GCbZcjBNsuQg20dqddnqdfbmzOj3e2sfA62tSWiTkT9jPuLBbd126W2s95xsG1Z9fosN998M9PT09RqNSqVYghtrVZbctultrPe6tUMKpaRWq3G5OQk+/fvZ3Jysu1tp6amVqlCm897bFtSvT7L9PQ01WqVQ4cOUa1WmZ6ePuPxxbZdbDvrPe+xrSOHDh0CoFqtMjk5yfj4OPX6LGvWjJ21bbVabWs7K5/32LZkT/eaNWO8+c1/BMCWLVvm2qemppiYmGDNmrG5sC607ULbWe+t+HxsSa+mmDu8aSPw18Ba4C+B/03tH4uI/cu8ls/H7oNmz3WjUZyjXKlUaDQamQfQ52MvKSKOprnENwOvA35BMecZwKeajy0XauuPTnq6bfiU9Rv7zcATEfGDNE2SDbhOerpt+JT1G3sbcGfL/Z2Sjki6TVLOx3VDqZOebhtOXQdb0rnA24F/TU23AK8ENgM14KZFnucFAwZEM9z79++fC7jDPdzK2GNfDTwcEScBIuJkRDwfEb8GPksxz/hZImJPRFzaTkeAlauTnm4bTl3PUirpLuCrEfFP6f54c3kfSX8FvD4iti3zGu4Vt1UyGr3iXXWeSfpt4C3A+1uaPyFpM8WaXsfnPWZmq6CrYEfEL4CXzmt7b1cVmVnXPPLMLEMO9ojoZIIEG34OduY6mSDB8uFgZ8zDRkeXT9vMmIeNji4HO1P1+izf/va354aNNk1MTMw97kEo+XKwR0QnEyTY8PNv7Ex52Oho88L3pfCQ0uExGkNKvcc2y5CDbZYhB9ssQw62WYYc7Ex5bPhoc7Az5LHh1law06SEpyQ92tJ2vqT7JD2ersdSuyR9WtKxNKHhJb0q3s7WnKjQY8NHW7t77M8BV81r2wUciIhNwIF0H4o50Dalyw6KyQ1tldRqtblJCZsXGz1tBTsivgX8ZF7zVmBvur0XeEdL++1RuB9YK2m8jGJtac29tacUtm7Gil/YnLQwImqSLkjt64CnWrabSW0+HlxFHhs+2npxEshCS4GcNWRU0g6KQ3UrSTO0u3ffOBfs5hrVDvRoaXusuKQNwL0R8dp0/yhwZdpbjwPfiIhXS/rHdPvO+dst8doeK26rxGPFl7MP2J5ubwfuaWl/X+odvxx4ZqlQm1n52joUl3QncCXwMkkzwN8Afw98QdI1wA+Bd6XN9wNTwDGKFTj/vOSazWwZPm2zFD4UHx4+FDezIeVgZ8zjxUeXg50hzyVuDnaGPJe4eZbSDHUyl3hzT97uAJZOt7f+8B47M/X67Nxc4kuNF+/0cN2H98PFwc5YM9zNs72aOl36x0sFDR8HOzPNQ+TF5hKHM5f+aef0zk63t/7zb+wM7dx5Xcu9O4Df3O906R8vFTScHOwR1+npnT4ddDj4ULyP+jGApNOlf7xU0HDyWPFSdDZWvNm73GgU45YrlQqNRsMBWRUeK2494B5mWw3+jb3KvBi9rQYHexW5h9lWi4PdR+5htl5Z9jf2IosF/IOk76UFAe6WtDa1b5BUl3Q4XT7Ty+KHjXuYbbUs2ysu6QrgZxRzhTcnMnwr8J8RcVrSxwEi4iPzJzxsu4gR6xW3fnKvOLDwYgER8bWIOJ3u3g9ctKISzawnyvhz118AX2m5PyHpkKRvSnrTYk+StEPSQUkHS6jBzFp01Xkm6XrgNMWAZChW+3hFRDwt6XXAlyW9JiKenf/ciNgD7EmvM+SH4maDZcV7bEnbgT8G/izSD/WI+GVEPJ1uPwQ8AbyqjELNrH0rCrakq4CPAG+PiF+0tL9c0jnp9kaKFTefLKNQM2vfsofiiywW8FHgPOA+SQD3R8QHgCuAv5V0Gnge+EBEzF+l00aQp1RaXT4JpBT5/LmrzBNU6vVZbr311rmFAZsj7Kanp9m48eKSKu7UaPy5yyPPbE7zBJX5QVzpCSoeF98/DrbNKTuI09PTHhffJw62Ab0/QcXj4leXz8fOVLezsyw0w2mnr+dx8f3jzrNSDFbnWUR9xZ1fu3ffCBTB3rJly9zv7f51dpVtNDrPHOxSDE6w6/XZuc6uweiFHjSjEWz/xs5MrVZzL7Q52DlpdoC5F9oc7Ey5F3q0OdgZaYZ29+4b54Ld7PxazUB7+Gj/ufOsFIPTedZP84ejwiCGezQ6z/x3bCvFQvOle670/vGh+Igr67DZ48IHi/fYI6rMhezr9dkzxoVXq9UVj1azcjjYI6jXyww53P230nnFb5D0o5b5w6daHvuopGOSjkp6W68Kt5VbyUL2S409X2y+dI8J75+Vzit+A/CziLhx3rYXA3cClwG/C/wH8KqIeH6Z93Cv+CqZfxbXli1bmJycnBvIMj4+fkYQ81sZ1L3iwMLzii9hK3BXmtRwGjhGEXIbUEudxeWVQYdXN7+xd6Ylfm6T1Pzvex3wVMs2M6ntLJ5XvD86WWZoJYfsNhhW+ueuW4C/AyJd30SxcIAW2HbBw2zPK95fO3de13LvDuC6Mx73yqDDbUXBjoiTzduSPgvcm+7OAOtbNr0IOLHi6mxgeOz5cFnpvOLjLXffCTR7zPcB2ySdJ2mCYl7x73RXovWDVwYdbu30is/NKw6cpJhX/EpgM8Vh9nHg/RFRS9tfT3FYfhq4NiK+ctaLnv0eQ34oPjy94jYaveI+CaQUDvbwGI1ge+SZWYYcbLMMOdhmGXKwzTLkYJtlyME2y5CDbZYhB9ssQw62WYYcbLMMOdhmGXKwzTLkYJtlyME2y5CDbZahlc4r/vmWOcWPSzqc2jdIqrc89pleFm9mC2tnzrPPAbuB25sNEfGnzduSbgKeadn+iYjYXFaBZta5ZYMdEd+StGGhxyQJeDfwB+WWNVwmJ8aZ+J21NBpQp5Em168wvrbCbKNBowFjlQqVsQqN2QZrxyo06sVMHs0VZ9eOVYq5PVJ7ZU2xTaPR8liLChSvsebM12y+XmWsMvdarKkwO/tTGg3mamq+d7Ou6en/mfsMUM7n6OYzrB2r8NPZxqKfo1Ipaqn9tHhsrFLU2GxvNJirE5j7zIeq1RV8w0MoIpa9ABuARxdovwI4OG+7nwOHgG8Cb2rz9cMXX3xp63KwnUx1u4zueyiW9GmqAa+IiKclvQ74sqTXRMSz858oaQewo8v3N7MFrLhXXNILgD8BPt9sS0v7PJ1uPwQ8AbxqoedHxJ6IuLSdidnMrDPd/LnrD4HvRcRMs0HSyyWdk25vpJhX/MnuSjSzTrXz5647gf8CXi1pRtI16aFtnHkYDsVv7iOSvgv8G/CBiGh3QT8zK4nnFTcbLp5X3GxUOdhmGXKwzTLkYJtlyME2y5CDbZYhB9ssQw62WYYcbLMMOdhmGXKwzTLkYJtlyME2y5CDbZYhB9ssQ+1MtLBe0tclVSU9JulDqf18SfdJejxdj6V2Sfq0pGOSjki6pNcfwszO1M4e+zTw4YiYBC4HPijpYmAXcCAiNgEH0n2AqymmRNpEMVnhLaVXbWZLWjbYEVGLiIfT7eeAKrAO2ArsTZvtBd6Rbm8Fbo/C/cBaSeOlV25mi+roN3ZaOGAL8ABwYUTUoAg/cEHabB3wVMvTZlKbma2StucVl/Ri4IvAtRHxbLEIyMKbLtB21pxmnlfcrHfa2mNLeiFFqO+IiC+l5pPNQ+x0fSq1zwDrW55+EXBi/mt6XnGz3mmnV1zArUA1Ij7Z8tA+YHu6vR24p6X9fal3/HLgmeYhu5mtkjbW1XojxaH0EeBwukwBL6XoDX88XZ+fthdwM8UqII8Al3rtLl98Ke3S1tpdnlfcbLh4XnGzUeVgm2XIwTbLkINtliEH2yxDDrZZhhxssww52GYZcrDNMuRgm2XIwTbLkINtliEH2yxDDrZZhhxssww52GYZcrDNMuRgm2Wo7emHe+zHwM/T9bB6GcNdPwz/Zxj2+mH5z/B77bzIQMx5BiDp4DBPRTzs9cPwf4Zhrx/K+ww+FDfLkINtlqFBCvaefhfQpWGvH4b/Mwx7/VDSZxiY39hmVp5B2mObWUn6HmxJV0k6KumYpF39rqddko5LekTSYUkHU9v5ku6T9Hi6Hut3na0k3SbplKRHW9oWrDmtvfbp9L0ckXRJ/yqfq3Wh+m+Q9KP0PRyWNNXy2EdT/Uclva0/Vf+GpPWSvi6pKukxSR9K7eV/B+2sA9SrC3AOxRpfG4Fzge8CF/ezpg5qPw68bF7bJ4Bd6fYu4OP9rnNefVcAlwCPLlczxfpsX6FYi+1y4IEBrf8G4LoFtr04/Xs6D5hI/87O6XP948Al6fZLgO+nOkv/Dvq9x74MOBYRT0bEr4C7gK19rqkbW4G96fZe4B19rOUsEfEt4CfzmhereStwexTuB9Y2l03ul0XqX8xW4K6I+GVETAPHKP699U1E1CLi4XT7OaAKrKMH30G/g70OeKrl/kxqGwYBfE3SQ5J2pLYLIy0ZnK4v6Ft17Vus5mH6bnamQ9XbWn7+DHT9kjYAW4AH6MF30O9ga4G2Yemmf0NEXAJcDXxQ0hX9Lqhkw/Ld3AK8EtgM1ICbUvvA1i/pxcAXgWsj4tmlNl2gra3P0O9gzwDrW+5fBJzoUy0diYgT6foUcDfFYd7J5qFSuj7VvwrbtljNQ/HdRMTJiHg+In4NfJbfHG4PZP2SXkgR6jsi4kupufTvoN/BfhDYJGlC0rnANmBfn2talqQXSXpJ8zbwVuBRitq3p822A/f0p8KOLFbzPuB9qWf2cuCZ5uHiIJn3m/OdFN8DFPVvk3SepAlgE/Cd1a6vlSQBtwLViPhky0PlfwcD0NM5RdE7+ARwfb/rabPmjRQ9rt8FHmvWDbwUOAA8nq7P73et8+q+k+Jw9f8o9gbXLFYzxWHgzel7eQS4dEDr/+dU35EUhPGW7a9P9R8Frh6A+t9IcSh9BDicLlO9+A488swsQ/0+FDezHnCwzTLkYJtlyME2y5CDbZYhB9ssQw62WYYcbLMM/T9ApZx7luUWMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Fill with borders\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/python-utils-scripts/test-folder/\"\n",
    "\n",
    "img = Image.open(prova_dir+\"preview7.png\")\n",
    "plt.imshow(img)\n",
    "\n",
    "img_with_border = ImageOps.expand(img,border=49,fill='black')\n",
    "plt.imshow(img_with_border)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esempio con test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/\"\n",
    "\n",
    "\n",
    "#transform = T.Compose([T.Grayscale(num_output_channels=1),\n",
    "                       #T.ToTensor(),\n",
    "                       #normalize])\n",
    "\n",
    "\n",
    "#input, label = Image.open(prova_dir+\"TEST42rgb.png\")\n",
    "\n",
    "# Get random sample from test set\n",
    "#idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[0]\n",
    "\n",
    "# Normalize and show image\n",
    "#input_show = (input - input.min())/(input.max() - input.min())\n",
    "#plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "#plt.imshow(input_show)\n",
    "#plt.axis('off')\n",
    "\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input.unsqueeze(0).to(dev))\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a model for dog detection\n",
    "\n",
    "In fine-tuning, we will include layers from a pre-trained model into our own network, then train the whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the `features` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test input\n",
    "alexnet.eval()\n",
    "test_x = torch.zeros(1, 3, 224, 224).to(dev)\n",
    "# Forward whole model\n",
    "print(alexnet(test_x).size())\n",
    "# Forward features only\n",
    "print(alexnet.features(test_x).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fine-tuned model\n",
    "class FineTunedAlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load AlexNet model\n",
    "        alexnet = models.alexnet(pretrained=True)\n",
    "        # Select feature extraction part\n",
    "        self.features = alexnet.features\n",
    "        self.fc1 = nn.Linear(256*6*6, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.output = nn.Linear(2048, 133)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.output(x),1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = FineTunedAlexNet()\n",
    "model = model.to(dev);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = dog_train_dataset[0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize training history\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get random sample from test set\n",
    "idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[idx]\n",
    "# Normalize and show image\n",
    "input_show = (input - input.min())/(input.max() - input.min())\n",
    "plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "plt.axis('off')\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input.unsqueeze(0).to(dev))\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using a pre-trained model as a feature extractor\n",
    "\n",
    "Fully-connected layer of models pre-trained on ImageNet can also work as generic image descriptors, because they compactly represent image content.\n",
    "\n",
    "Feature extraction means that we pass an image to a CNN model, but only get the output of a fully-connected layer, and use that output instead of the fully image. Then, we train a simpler classifier (SVM or MLP) on the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction in PyTorch may be tricky sometimes, depending on how the model is defined. We will see two methods to extract features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Modifying layers\n",
    "\n",
    "Let's see the Alexnet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "alexnet.eval()\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "alexnet(torch.zeros(1, 3, 224, 224).to(dev)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's suppose we want the output of the last FC layer (before classification). In practice, we want the output of layer `5` inside the `classifier` block. The problem is that `classifier` is a `Sequential`, so we cannot directly get the output of an intermediate layer.\n",
    "\n",
    "One solution is to modify the `classifier` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classifier block\n",
    "alexnet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential children\n",
    "alexnet.classifier.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert generator to list\n",
    "list(alexnet.classifier.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the final linear layer\n",
    "new_classifier_modules = list(alexnet.classifier.children())\n",
    "new_classifier_modules = new_classifier_modules[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the new list of modules\n",
    "new_classifier_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Sequential container\n",
    "new_classifier = nn.Sequential(*new_classifier_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the classifier\n",
    "alexnet.classifier = new_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "test_out = alexnet(torch.zeros(1, 3, 224, 224).to(dev))\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep output for later\n",
    "features_1 = test_out.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, our `alexnet` model now returns directly the output of a fully-connected layer. However, this was easy because `classifier` is the last block of the model, so there's nothing after it that depends on it.\n",
    "\n",
    "In other cases, it may not be so easy. For example, consider the [`inception_v3`](https://github.com/pytorch/vision/blob/master/torchvision/models/inception.py) model.\n",
    "\n",
    "In that case, layers are defined as individual class properties, and the `forward()` method calls them in turn. If we want to extract features, we should modify the `forward()` method. It can be done, but it's not trivial, and there's a cleaner way: **hooks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Forward hooks\n",
    "\n",
    "Hooks are callback functions associated to `nn.Module`s, that are invoked during forward (_forward hook_) or during backpropagation (_backward hook_).\n",
    "\n",
    "When you _register_ a hook, you ask the model to call your function whenever a layer processes input data. Your function will receive the input and output of the module.\n",
    "\n",
    "Another way to implement feature extraction is to set up a forward hook on our target layer, get the layer's output, and save it in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "alexnet.eval()\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction class\n",
    "class FeatureExtractor:\n",
    "    \n",
    "    # Constructor: receives model and target layer\n",
    "    def __init__(self, model, layer):\n",
    "        # Save model\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        # Internal variable to store target features\n",
    "        self.features = None\n",
    "        # Define hook\n",
    "        def forward_hook(module, input, output):\n",
    "            # Copy features\n",
    "            self.features = output.clone()\n",
    "        # Register hook\n",
    "        layer.register_forward_hook(forward_hook)\n",
    "        \n",
    "    # Function interface\n",
    "    def __call__(self, input):\n",
    "        with torch.no_grad():\n",
    "            # Forward through model\n",
    "            self.model(input)\n",
    "        # Return features\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get reference to target layer?\n",
    "\n",
    "Just traverse the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extractor\n",
    "feat_extr = FeatureExtractor(alexnet, alexnet.classifier[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "test_out = feat_extr(torch.zeros(1, 3, 224, 224).to(dev))\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare features\n",
    "features_2 = test_out\n",
    "print((features_1 - features_2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our feature extraction to process all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of features\n",
    "num_features = feat_extr(dog_train_dataset[0][0].unsqueeze(0).to(dev)).numel()\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data matrices (num_samples x num_features)\n",
    "datasets = {\"train\": dog_train_dataset, \"val\": dog_val_dataset, \"test\": dog_test_dataset}\n",
    "features = {\"train\": torch.Tensor(len(dog_train_dataset), num_features),\n",
    "            \"val\":   torch.Tensor(len(dog_val_dataset), num_features),\n",
    "            \"test\":  torch.Tensor(len(dog_test_dataset), num_features)\n",
    "           }\n",
    "labels = {\"train\": torch.LongTensor(len(dog_train_dataset)),\n",
    "          \"val\":   torch.LongTensor(len(dog_val_dataset)),\n",
    "          \"test\":  torch.LongTensor(len(dog_test_dataset))\n",
    "         }\n",
    "# Fill the features for each split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"Processing {split} split\")\n",
    "    # Process each sample in the split\n",
    "    for i in range(len(datasets[split])):\n",
    "        # Get sample\n",
    "        sample,label = datasets[split][i]\n",
    "        # Compute features\n",
    "        sample = sample.unsqueeze(0).to(dev)\n",
    "        feats = feat_extr(sample)\n",
    "        # Copy features\n",
    "        features[split][i] = feats\n",
    "        labels[split][i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our data formatted as in our initial examples with linear regression and classification. However, we can still use the standard `DataLoader` interface, by wrapping our matrices as `TensorDataset` objects. In a `TensorDataset`, you can pass any kind of tensors as source data, and sample selection is performed by indexing the first dimension (in our case, rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from torch.utils.data import TensorDataset\n",
    "# Prepare tensor datasets\n",
    "tensor_datasets = {\n",
    "    split: TensorDataset(features[split], labels[split]) for split in features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data loaders\n",
    "loaders = {\"train\": DataLoader(dataset=tensor_datasets[\"train\"], batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True),\n",
    "           \"val\":   DataLoader(dataset=tensor_datasets[\"val\"],   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\n",
    "           \"test\":  DataLoader(dataset=tensor_datasets[\"test\"],  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a linear classifier on the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = nn.Linear(num_features, num_classes)\n",
    "model = model.to(dev);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = tensor_datasets[\"train\"][0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training history\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get random sample from test set\n",
    "idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[idx]\n",
    "# Normalize and show image\n",
    "input_show = (input - input.min())/(input.max() - input.min())\n",
    "plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "plt.axis('off')\n",
    "# Extract features\n",
    "input = feat_extr(input.unsqueeze(0).to(dev))\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input)\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "author": "ML1819",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
