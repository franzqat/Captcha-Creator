{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING RETE NEURALE - classificazione captcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform\n",
    "import torchvision.transforms as T\n",
    "# Define single transforms\n",
    "\n",
    "# Note: transforms can also be regular functions\n",
    "def normalize_(x):\n",
    "    # Set values\n",
    "    x[x > 0.5] = 1\n",
    "    x[x <= 0.5] = -1\n",
    "    # Return\n",
    "    return x\n",
    "\n",
    "\n",
    "normalize = normalize_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_(img):   #resize 48x48 \n",
    "    size = 48,48\n",
    "    img = img.resize(size)\n",
    "    return img\n",
    "\n",
    "resize = resize_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Grayscale(num_output_channels=1),\n",
    "                       resize,\n",
    "                       T.ToTensor(),\n",
    "                       normalize])\n",
    "\n",
    "                       #,T.Normalize(mean=0,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet class map\n",
    "class_names = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I',9:\"J\",10:\"K\",11:\"L\",12:\"M\",13:\"N\",14:\"O\",15:\"P\",16:\"Q\",17:\"R\",18:\"S\",19:\"T\",20:\"U\",21:\"V\",22:\"W\",23:\"X\",24:\"Y\",25:\"Z\"};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "#classi = i for i in range(26) : k for k in string.ascii_uppercase\n",
    "string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from PIL import Image, ImageChops\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Dog Detector\n",
    "\n",
    "While looking at the class list, you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained, we need only to check if the returned class prediction is a value between 151 and 268 (inclusive).\n",
    "\n",
    "We use these ideas to define the `dog_detector` function below, which returns `True` if a dog is detected in an image (and `False` if not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "root_dir = \"./output/\"\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now, we will create a CNN that classifies numbers. We will train our model _from scratch_, i.e. with randomly-initialized weights.\n",
    "\n",
    "The task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have great difficulty in distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. classes: 26\n",
      "Num. train samples: 13884\n",
      "Num. valid. samples: 4628\n",
      "Num. test samples: 4628\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import PIL\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "# Instantiate datasets\n",
    "dog_train_dataset = ImageFolder(os.path.join(root_dir,  \"train\"), transform) #, loader=loader)\n",
    "dog_val_dataset = ImageFolder(os.path.join(root_dir,  \"val\"), transform) #, loader=loader)\n",
    "dog_test_dataset = ImageFolder(os.path.join(root_dir,  \"test\"), transform) #, loader=loader)\n",
    "\n",
    "# Get number of classes (we'll need it in the model)\n",
    "num_classes = len(dog_train_dataset.classes)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Num. classes: {num_classes}\")\n",
    "print(f\"Num. train samples: {len(dog_train_dataset)}\")\n",
    "print(f\"Num. valid. samples: {len(dog_val_dataset)}\")\n",
    "print(f\"Num. test samples: {len(dog_test_dataset)}\")\n",
    "\n",
    "\n",
    "# Instantiate data loaders\n",
    "loaders = {\"train\": DataLoader(dataset=dog_train_dataset, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True),\n",
    "           \"val\":   DataLoader(dataset=dog_val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\n",
    "           \"test\":  DataLoader(dataset=dog_test_dataset,  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 48])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convolutional layer\n",
    "class ConvLayer(nn.Sequential):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.add_module('conv', nn.Conv2d(in_features, out_features, kernel_size=3))\n",
    "        self.add_module('relu', nn.ReLU())\n",
    "        self.add_module('pool', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "# Convolutional layer\n",
    "class ConvLayerBN(nn.Sequential):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.add_module('conv', nn.Conv2d(in_features, out_features, kernel_size=3))\n",
    "        self.add_module('relu', nn.ReLU())\n",
    "        self.add_module('bn', nn.BatchNorm2d(out_features))\n",
    "        self.add_module('pool', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "# Define model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call parent\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.convs = nn.Sequential(\n",
    "            ConvLayerBN(1, 32),\n",
    "            ConvLayerBN(32, 128)#,\n",
    "           # ConvLayerBN(256, 256),\n",
    "          #  ConvLayerBN(256, 512),\n",
    "          #  ConvLayerBN(512, 512)\n",
    "        )\n",
    "        # Computing encoding size\n",
    "        self.convs.eval()\n",
    "        #test_x = torch.zeros(1, 3, 224, 244)\n",
    "        #test_x = torch.zeros(1, 1, 32,32)\n",
    "        test_x = torch.zeros(1, 1, 48,48) ##GUARDACASO E' LA DIMENSIONE IN PIXEL\n",
    "        test_x = self.convs(test_x)\n",
    "        encoding_size = test_x.numel()\n",
    "        print(f\"Encoding size: {encoding_size}\")\n",
    "        # FC layers\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(encoding_size, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Compute output\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fcs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding size: 12800\n",
      "Model(\n",
      "  (convs): Sequential(\n",
      "    (0): ConvLayerBN(\n",
      "      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): ConvLayerBN(\n",
      "      (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (fcs): Sequential(\n",
      "    (0): Linear(in_features=12800, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=2048, out_features=26, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = Model()\n",
    "model = model.to(dev);\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output size: torch.Size([1, 26])\n"
     ]
    }
   ],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = dog_train_dataset[0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "save_every = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, TL=2.8363, TA=0.2069, VL=2.7054, VA=0.2807, ŦL=2.6993, ŦA=0.2854\n",
      "Epoch: 2, TL=2.6823, TA=0.2391, VL=2.5181, VA=0.3389, ŦL=2.5127, ŦA=0.3309\n",
      "Epoch: 3, TL=2.4990, TA=0.2838, VL=2.3122, VA=0.3941, ŦL=2.3074, ŦA=0.3797\n",
      "Epoch: 4, TL=2.2996, TA=0.3340, VL=2.0821, VA=0.4512, ŦL=2.0770, ŦA=0.4444\n",
      "Epoch: 5, TL=2.0844, TA=0.3928, VL=1.8528, VA=0.5081, ŦL=1.8487, ŦA=0.5137\n",
      "Epoch: 6, TL=1.8716, TA=0.4595, VL=1.6307, VA=0.5707, ŦL=1.6293, ŦA=0.5717\n",
      "Epoch: 7, TL=1.6827, TA=0.5081, VL=1.4393, VA=0.6355, ŦL=1.4399, ŦA=0.6394\n",
      "Epoch: 8, TL=1.4934, TA=0.5676, VL=1.2566, VA=0.6842, ŦL=1.2590, ŦA=0.6906\n",
      "Epoch: 9, TL=1.3309, TA=0.6133, VL=1.1050, VA=0.7261, ŦL=1.1083, ŦA=0.7242\n",
      "Epoch: 10, TL=1.1826, TA=0.6583, VL=0.9788, VA=0.7641, ŦL=0.9810, ŦA=0.7628\n",
      "Epoch: 11, TL=1.0547, TA=0.6972, VL=0.8573, VA=0.7894, ŦL=0.8594, ŦA=0.7925\n",
      "Epoch: 12, TL=0.9435, TA=0.7344, VL=0.7668, VA=0.8121, ŦL=0.7702, ŦA=0.8091\n",
      "Epoch: 13, TL=0.8478, TA=0.7591, VL=0.6951, VA=0.8269, ŦL=0.6993, ŦA=0.8259\n",
      "Epoch: 14, TL=0.7692, TA=0.7802, VL=0.6326, VA=0.8440, ŦL=0.6346, ŦA=0.8424\n",
      "Epoch: 15, TL=0.6901, TA=0.8101, VL=0.5666, VA=0.8586, ŦL=0.5699, ŦA=0.8552\n",
      "Epoch: 16, TL=0.6288, TA=0.8235, VL=0.5181, VA=0.8728, ŦL=0.5179, ŦA=0.8691\n",
      "Epoch: 17, TL=0.5764, TA=0.8413, VL=0.4917, VA=0.8728, ŦL=0.4928, ŦA=0.8734\n",
      "Epoch: 18, TL=0.5317, TA=0.8514, VL=0.4489, VA=0.8886, ŦL=0.4491, ŦA=0.8887\n",
      "Epoch: 19, TL=0.4886, TA=0.8637, VL=0.4142, VA=0.8955, ŦL=0.4160, ŦA=0.8923\n",
      "Epoch: 20, TL=0.4522, TA=0.8761, VL=0.3838, VA=0.9017, ŦL=0.3854, ŦA=0.8984\n",
      "Epoch: 21, TL=0.4134, TA=0.8872, VL=0.3659, VA=0.9028, ŦL=0.3674, ŦA=0.9025\n",
      "Epoch: 22, TL=0.3844, TA=0.8965, VL=0.3400, VA=0.9093, ŦL=0.3421, ŦA=0.9100\n",
      "Epoch: 23, TL=0.3536, TA=0.9079, VL=0.3189, VA=0.9134, ŦL=0.3197, ŦA=0.9116\n",
      "Epoch: 24, TL=0.3329, TA=0.9120, VL=0.3067, VA=0.9159, ŦL=0.3079, ŦA=0.9169\n",
      "Epoch: 25, TL=0.3165, TA=0.9138, VL=0.2908, VA=0.9233, ŦL=0.2908, ŦA=0.9226\n",
      "Epoch: 26, TL=0.2913, TA=0.9268, VL=0.2777, VA=0.9226, ŦL=0.2782, ŦA=0.9231\n",
      "Epoch: 27, TL=0.2709, TA=0.9295, VL=0.2744, VA=0.9272, ŦL=0.2758, ŦA=0.9235\n",
      "Epoch: 28, TL=0.2588, TA=0.9313, VL=0.2573, VA=0.9278, ŦL=0.2592, ŦA=0.9274\n",
      "Epoch: 29, TL=0.2412, TA=0.9401, VL=0.2486, VA=0.9341, ŦL=0.2521, ŦA=0.9282\n",
      "Epoch: 30, TL=0.2257, TA=0.9430, VL=0.2366, VA=0.9364, ŦL=0.2384, ŦA=0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  # Checkpoint\\n    if epoch % save_every == 0:\\n        # Prepare generator state\\n        g_state_dict = g_net.state_dict()\\n        for k,v in g_state_dict.items():\\n            g_state_dict[k] = v.cpu()\\n        # Prepare generator state\\n        d_state_dict = d_net.state_dict()\\n        for k,v in d_state_dict.items():\\n            d_state_dict[k] = v.cpu()\\n        # Save checkpoint\\n        checkpoint_data = {\"g_state_dict\": g_state_dict, \"d_state_dict\": d_state_dict}\\n        torch.save(checkpoint_data, f\"checkpoint-{epoch}.pth\")\\n       '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize training history\n",
    "\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy\n",
    "   \n",
    "\"\"\"  # Checkpoint\n",
    "    if epoch % save_every == 0:\n",
    "        # Prepare generator state\n",
    "        g_state_dict = g_net.state_dict()\n",
    "        for k,v in g_state_dict.items():\n",
    "            g_state_dict[k] = v.cpu()\n",
    "        # Prepare generator state\n",
    "        d_state_dict = d_net.state_dict()\n",
    "        for k,v in d_state_dict.items():\n",
    "            d_state_dict[k] = v.cpu()\n",
    "        # Save checkpoint\n",
    "        checkpoint_data = {\"g_state_dict\": g_state_dict, \"d_state_dict\": d_state_dict}\n",
    "        torch.save(checkpoint_data, f\"checkpoint-{epoch}.pth\")\n",
    "       \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.9334\n"
     ]
    }
   ],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "# Define root directory\n",
    "save_path = f\"./modello{num_epochs}.pt\"\n",
    "modello_salvato = model.state_dict()\n",
    "torch.save(modello_salvato, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/python-utils-scripts/\"\n",
    "\n",
    "\n",
    "transform_test = T.Compose([T.Grayscale(num_output_channels=1),\n",
    "                           trim,\n",
    "                           T.ToTensor(),\n",
    "                           normalize])\n",
    "\n",
    "\n",
    "img = Image.open(prova_dir+\"prova-113.png\")\n",
    "img = transform_test(img)\n",
    "print(img.size())\n",
    "\n",
    "\n",
    "img = Image.open(prova_dir+\"prova-bin-resized.png\")\n",
    "img = transform_test(img)\n",
    "print(img.size())\n",
    "#plt.imshow(img)\n",
    "#size = 32,32\n",
    "#img = img.resize(size)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 8 (correct: )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/python-utils-scripts/test-folder/\"\n",
    "\n",
    "img = Image.open(prova_dir+\"preview12.png\")\n",
    "plt.imshow(img)\n",
    "img = img.convert('1')\n",
    "\n",
    "\"\"\"\n",
    "img = trim(img)\n",
    "size = 48,48\n",
    "img = img.resize(size)\n",
    "\"\"\"\n",
    "plt.imshow(img)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "transform_imageprova = T.Compose([\n",
    "                    T.Grayscale(num_output_channels=1),\n",
    "                    #resize_,\n",
    "                    trim,\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                    ])\n",
    "\"\"\"\n",
    "# Transform image\n",
    "#img = transform_imageprova(img)\n",
    "\n",
    "label = \"\"\n",
    "input = transform(img)\n",
    "#input = transform(img)\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input.unsqueeze(0).to(dev))\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {class_names[pred]} (correct: {label})\")\n",
    "#plt.show(input)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xc09ca20>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Fill with borders\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/python-utils-scripts/test-folder/\"\n",
    "\n",
    "img = Image.open(prova_dir+\"preview7.png\")\n",
    "plt.imshow(img)\n",
    "\n",
    "img_with_border = ImageOps.expand(img,border=49,fill='black')\n",
    "plt.imshow(img_with_border)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esempio con test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "# Define root directory\n",
    "prova_dir = \"F:/Programmazione/UO-Captcha-breaker/\"\n",
    "\n",
    "\n",
    "#transform = T.Compose([T.Grayscale(num_output_channels=1),\n",
    "                       #T.ToTensor(),\n",
    "                       #normalize])\n",
    "\n",
    "\n",
    "#input, label = Image.open(prova_dir+\"TEST42rgb.png\")\n",
    "\n",
    "# Get random sample from test set\n",
    "#idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[0]\n",
    "\n",
    "# Normalize and show image\n",
    "#input_show = (input - input.min())/(input.max() - input.min())\n",
    "#plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "#plt.imshow(input_show)\n",
    "#plt.axis('off')\n",
    "\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input.unsqueeze(0).to(dev))\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a model for dog detection\n",
    "\n",
    "In fine-tuning, we will include layers from a pre-trained model into our own network, then train the whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the `features` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test input\n",
    "alexnet.eval()\n",
    "test_x = torch.zeros(1, 3, 224, 224).to(dev)\n",
    "# Forward whole model\n",
    "print(alexnet(test_x).size())\n",
    "# Forward features only\n",
    "print(alexnet.features(test_x).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fine-tuned model\n",
    "class FineTunedAlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load AlexNet model\n",
    "        alexnet = models.alexnet(pretrained=True)\n",
    "        # Select feature extraction part\n",
    "        self.features = alexnet.features\n",
    "        self.fc1 = nn.Linear(256*6*6, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.output = nn.Linear(2048, 133)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.output(x),1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = FineTunedAlexNet()\n",
    "model = model.to(dev);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = dog_train_dataset[0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize training history\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get random sample from test set\n",
    "idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[idx]\n",
    "# Normalize and show image\n",
    "input_show = (input - input.min())/(input.max() - input.min())\n",
    "plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "plt.axis('off')\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input.unsqueeze(0).to(dev))\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using a pre-trained model as a feature extractor\n",
    "\n",
    "Fully-connected layer of models pre-trained on ImageNet can also work as generic image descriptors, because they compactly represent image content.\n",
    "\n",
    "Feature extraction means that we pass an image to a CNN model, but only get the output of a fully-connected layer, and use that output instead of the fully image. Then, we train a simpler classifier (SVM or MLP) on the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction in PyTorch may be tricky sometimes, depending on how the model is defined. We will see two methods to extract features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Modifying layers\n",
    "\n",
    "Let's see the Alexnet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "alexnet.eval()\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "alexnet(torch.zeros(1, 3, 224, 224).to(dev)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's suppose we want the output of the last FC layer (before classification). In practice, we want the output of layer `5` inside the `classifier` block. The problem is that `classifier` is a `Sequential`, so we cannot directly get the output of an intermediate layer.\n",
    "\n",
    "One solution is to modify the `classifier` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classifier block\n",
    "alexnet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential children\n",
    "alexnet.classifier.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert generator to list\n",
    "list(alexnet.classifier.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the final linear layer\n",
    "new_classifier_modules = list(alexnet.classifier.children())\n",
    "new_classifier_modules = new_classifier_modules[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the new list of modules\n",
    "new_classifier_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Sequential container\n",
    "new_classifier = nn.Sequential(*new_classifier_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the classifier\n",
    "alexnet.classifier = new_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "test_out = alexnet(torch.zeros(1, 3, 224, 224).to(dev))\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep output for later\n",
    "features_1 = test_out.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, our `alexnet` model now returns directly the output of a fully-connected layer. However, this was easy because `classifier` is the last block of the model, so there's nothing after it that depends on it.\n",
    "\n",
    "In other cases, it may not be so easy. For example, consider the [`inception_v3`](https://github.com/pytorch/vision/blob/master/torchvision/models/inception.py) model.\n",
    "\n",
    "In that case, layers are defined as individual class properties, and the `forward()` method calls them in turn. If we want to extract features, we should modify the `forward()` method. It can be done, but it's not trivial, and there's a cleaner way: **hooks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Forward hooks\n",
    "\n",
    "Hooks are callback functions associated to `nn.Module`s, that are invoked during forward (_forward hook_) or during backpropagation (_backward hook_).\n",
    "\n",
    "When you _register_ a hook, you ask the model to call your function whenever a layer processes input data. Your function will receive the input and output of the module.\n",
    "\n",
    "Another way to implement feature extraction is to set up a forward hook on our target layer, get the layer's output, and save it in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet = alexnet.to(dev)\n",
    "alexnet.eval()\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction class\n",
    "class FeatureExtractor:\n",
    "    \n",
    "    # Constructor: receives model and target layer\n",
    "    def __init__(self, model, layer):\n",
    "        # Save model\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        # Internal variable to store target features\n",
    "        self.features = None\n",
    "        # Define hook\n",
    "        def forward_hook(module, input, output):\n",
    "            # Copy features\n",
    "            self.features = output.clone()\n",
    "        # Register hook\n",
    "        layer.register_forward_hook(forward_hook)\n",
    "        \n",
    "    # Function interface\n",
    "    def __call__(self, input):\n",
    "        with torch.no_grad():\n",
    "            # Forward through model\n",
    "            self.model(input)\n",
    "        # Return features\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get reference to target layer?\n",
    "\n",
    "Just traverse the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extractor\n",
    "feat_extr = FeatureExtractor(alexnet, alexnet.classifier[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test output\n",
    "test_out = feat_extr(torch.zeros(1, 3, 224, 224).to(dev))\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare features\n",
    "features_2 = test_out\n",
    "print((features_1 - features_2).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our feature extraction to process all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of features\n",
    "num_features = feat_extr(dog_train_dataset[0][0].unsqueeze(0).to(dev)).numel()\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data matrices (num_samples x num_features)\n",
    "datasets = {\"train\": dog_train_dataset, \"val\": dog_val_dataset, \"test\": dog_test_dataset}\n",
    "features = {\"train\": torch.Tensor(len(dog_train_dataset), num_features),\n",
    "            \"val\":   torch.Tensor(len(dog_val_dataset), num_features),\n",
    "            \"test\":  torch.Tensor(len(dog_test_dataset), num_features)\n",
    "           }\n",
    "labels = {\"train\": torch.LongTensor(len(dog_train_dataset)),\n",
    "          \"val\":   torch.LongTensor(len(dog_val_dataset)),\n",
    "          \"test\":  torch.LongTensor(len(dog_test_dataset))\n",
    "         }\n",
    "# Fill the features for each split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"Processing {split} split\")\n",
    "    # Process each sample in the split\n",
    "    for i in range(len(datasets[split])):\n",
    "        # Get sample\n",
    "        sample,label = datasets[split][i]\n",
    "        # Compute features\n",
    "        sample = sample.unsqueeze(0).to(dev)\n",
    "        feats = feat_extr(sample)\n",
    "        # Copy features\n",
    "        features[split][i] = feats\n",
    "        labels[split][i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our data formatted as in our initial examples with linear regression and classification. However, we can still use the standard `DataLoader` interface, by wrapping our matrices as `TensorDataset` objects. In a `TensorDataset`, you can pass any kind of tensors as source data, and sample selection is performed by indexing the first dimension (in our case, rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from torch.utils.data import TensorDataset\n",
    "# Prepare tensor datasets\n",
    "tensor_datasets = {\n",
    "    split: TensorDataset(features[split], labels[split]) for split in features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data loaders\n",
    "loaders = {\"train\": DataLoader(dataset=tensor_datasets[\"train\"], batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True),\n",
    "           \"val\":   DataLoader(dataset=tensor_datasets[\"val\"],   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\n",
    "           \"test\":  DataLoader(dataset=tensor_datasets[\"test\"],  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train a linear classifier on the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = nn.Linear(num_features, num_classes)\n",
    "model = model.to(dev);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model output\n",
    "model.eval()\n",
    "test_input = tensor_datasets[\"train\"][0][0].unsqueeze(0).to(dev)\n",
    "print(\"Model output size:\", model(test_input).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.optim\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training history\n",
    "loss_history = {'train': [], 'val': [], 'test': []}\n",
    "accuracy_history = {'train': [], 'val': [], 'test': []}\n",
    "# Keep track of best validation accuracy\n",
    "best_val_accuracy = 0\n",
    "test_accuracy_at_best_val = 0\n",
    "# Start training\n",
    "for epoch in range(100):\n",
    "    # Initialize accumulators for computing average loss/accuracy\n",
    "    epoch_loss_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_loss_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_sum = {'train': 0, 'val': 0, 'test': 0}\n",
    "    epoch_accuracy_cnt = {'train': 0, 'val': 0, 'test': 0}\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        # Process all data in split\n",
    "        for (input,target) in loaders[split]:\n",
    "            # Move to device\n",
    "            input = input.to(dev)\n",
    "            target = target.to(dev)\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            # Update loss sum\n",
    "            epoch_loss_sum[split] += loss.item()\n",
    "            epoch_loss_cnt[split] += 1\n",
    "            # Compute accuracy\n",
    "            _,pred = output.max(1)\n",
    "            correct = pred.eq(target).sum().item()\n",
    "            accuracy = correct/input.size(0)\n",
    "            # Update accuracy sum\n",
    "            epoch_accuracy_sum[split] += accuracy\n",
    "            epoch_accuracy_cnt[split] += 1\n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    # Compute average epoch loss/accuracy\n",
    "    avg_train_loss = epoch_loss_sum[\"train\"]/epoch_loss_cnt[\"train\"]\n",
    "    avg_train_accuracy = epoch_accuracy_sum[\"train\"]/epoch_accuracy_cnt[\"train\"]\n",
    "    avg_val_loss = epoch_loss_sum[\"val\"]/epoch_loss_cnt[\"val\"]\n",
    "    avg_val_accuracy = epoch_accuracy_sum[\"val\"]/epoch_accuracy_cnt[\"val\"]\n",
    "    avg_test_loss = epoch_loss_sum[\"test\"]/epoch_loss_cnt[\"test\"]\n",
    "    avg_test_accuracy = epoch_accuracy_sum[\"test\"]/epoch_accuracy_cnt[\"test\"]\n",
    "    print(f\"Epoch: {epoch+1}, TL={avg_train_loss:.4f}, TA={avg_train_accuracy:.4f}, VL={avg_val_loss:.4f}, VA={avg_val_accuracy:.4f}, ŦL={avg_test_loss:.4f}, ŦA={avg_test_accuracy:.4f}\")\n",
    "    # Add to histories\n",
    "    loss_history[\"train\"].append(avg_train_loss)\n",
    "    loss_history[\"val\"].append(avg_val_loss)\n",
    "    loss_history[\"test\"].append(avg_test_loss)\n",
    "    accuracy_history[\"train\"].append(avg_train_accuracy)\n",
    "    accuracy_history[\"val\"].append(avg_val_accuracy)\n",
    "    accuracy_history[\"test\"].append(avg_test_accuracy)\n",
    "    # Check best validation\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        # Update best validation\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        test_accuracy_at_best_val = avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy at best validation accuracy\n",
    "print(f\"Final test accuracy {test_accuracy_at_best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, loss_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, loss_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "x = torch.arange(1, len(loss_history[\"train\"])+1).numpy()\n",
    "plt.plot(x, accuracy_history[\"train\"], label=\"train\")\n",
    "plt.plot(x, accuracy_history[\"val\"], label=\"val\")\n",
    "plt.plot(x, accuracy_history[\"test\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get random sample from test set\n",
    "idx = random.randint(0, len(dog_test_dataset)-1)\n",
    "input, label = dog_test_dataset[idx]\n",
    "# Normalize and show image\n",
    "input_show = (input - input.min())/(input.max() - input.min())\n",
    "plt.imshow(input_show.permute(1,2,0).numpy())\n",
    "plt.axis('off')\n",
    "# Extract features\n",
    "input = feat_extr(input.unsqueeze(0).to(dev))\n",
    "# Predict class\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input)\n",
    "_,pred = output.max(1)\n",
    "pred = pred.item()\n",
    "print(f\"Predicted: {pred} (correct: {label})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "author": "ML1819",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
